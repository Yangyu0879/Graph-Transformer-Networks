{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594b2466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from model.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from model import GTN\n",
    "from utils import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dac8e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "node_dim = 64\n",
    "num_channels = 2\n",
    "lr = 0.005\n",
    "weight_decay = 0.001\n",
    "num_layers = 2\n",
    "norm = True\n",
    "adaptive_lr = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca1f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ACM/node_features.pkl', 'rb') as f:\n",
    "    node_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c30bf4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26560ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8994, 1902)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b73b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ACM/edges.pkl', 'rb') as f:\n",
    "    edges = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678be51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<8994x8994 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 9936 stored elements in Compressed Sparse Row format>,\n",
       " <8994x8994 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 9936 stored elements in Compressed Sparse Column format>,\n",
       " <8994x8994 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 3025 stored elements in Compressed Sparse Row format>,\n",
       " <8994x8994 sparse matrix of type '<class 'numpy.int32'>'\n",
       " \twith 3025 stored elements in Compressed Sparse Column format>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f1c8310",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/ACM/labels.pkl', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc756fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 826,    0],\n",
       "        [1823,    0],\n",
       "        [1382,    0],\n",
       "        ...,\n",
       "        [2480,    2],\n",
       "        [2596,    2],\n",
       "        [2958,    2]], dtype=int64),\n",
       " array([[1770,    0],\n",
       "        [ 888,    0],\n",
       "        [1737,    0],\n",
       "        [1793,    0],\n",
       "        [2389,    0],\n",
       "        [1454,    0],\n",
       "        [1600,    0],\n",
       "        [2374,    0],\n",
       "        [1067,    0],\n",
       "        [1125,    0],\n",
       "        [ 963,    0],\n",
       "        [1551,    0],\n",
       "        [ 991,    0],\n",
       "        [1358,    0],\n",
       "        [1101,    0],\n",
       "        [1913,    0],\n",
       "        [1677,    0],\n",
       "        [1540,    0],\n",
       "        [1909,    0],\n",
       "        [1038,    0],\n",
       "        [1042,    0],\n",
       "        [1452,    0],\n",
       "        [1560,    0],\n",
       "        [ 979,    0],\n",
       "        [2361,    0],\n",
       "        [1837,    0],\n",
       "        [1568,    0],\n",
       "        [1941,    0],\n",
       "        [1815,    0],\n",
       "        [1258,    0],\n",
       "        [1751,    0],\n",
       "        [1655,    0],\n",
       "        [1859,    0],\n",
       "        [1569,    0],\n",
       "        [1756,    0],\n",
       "        [2352,    0],\n",
       "        [1583,    0],\n",
       "        [1260,    0],\n",
       "        [ 894,    0],\n",
       "        [1184,    0],\n",
       "        [ 806,    0],\n",
       "        [1002,    0],\n",
       "        [1489,    0],\n",
       "        [1037,    0],\n",
       "        [1699,    0],\n",
       "        [2356,    0],\n",
       "        [1870,    0],\n",
       "        [1051,    0],\n",
       "        [1702,    0],\n",
       "        [1201,    0],\n",
       "        [1864,    0],\n",
       "        [ 959,    0],\n",
       "        [1669,    0],\n",
       "        [1088,    0],\n",
       "        [1105,    0],\n",
       "        [1460,    0],\n",
       "        [1490,    0],\n",
       "        [2365,    0],\n",
       "        [ 807,    0],\n",
       "        [1610,    0],\n",
       "        [1535,    0],\n",
       "        [1734,    0],\n",
       "        [1139,    0],\n",
       "        [1730,    0],\n",
       "        [1194,    0],\n",
       "        [ 995,    0],\n",
       "        [ 993,    0],\n",
       "        [1447,    0],\n",
       "        [1746,    0],\n",
       "        [1717,    0],\n",
       "        [1096,    0],\n",
       "        [1090,    0],\n",
       "        [2385,    0],\n",
       "        [ 958,    0],\n",
       "        [1007,    0],\n",
       "        [1476,    0],\n",
       "        [ 821,    0],\n",
       "        [1244,    0],\n",
       "        [1062,    0],\n",
       "        [1130,    0],\n",
       "        [2392,    0],\n",
       "        [1190,    0],\n",
       "        [1028,    0],\n",
       "        [2399,    0],\n",
       "        [1639,    0],\n",
       "        [ 988,    0],\n",
       "        [ 871,    0],\n",
       "        [1005,    0],\n",
       "        [1053,    0],\n",
       "        [1667,    0],\n",
       "        [1486,    0],\n",
       "        [1692,    0],\n",
       "        [ 837,    0],\n",
       "        [1904,    0],\n",
       "        [1697,    0],\n",
       "        [1083,    0],\n",
       "        [1473,    0],\n",
       "        [1939,    0],\n",
       "        [1645,    0],\n",
       "        [1658,    0],\n",
       "        [ 292,    1],\n",
       "        [2021,    1],\n",
       "        [1231,    1],\n",
       "        [2278,    1],\n",
       "        [2322,    1],\n",
       "        [2285,    1],\n",
       "        [2560,    1],\n",
       "        [2676,    1],\n",
       "        [ 153,    1],\n",
       "        [1333,    1],\n",
       "        [2343,    1],\n",
       "        [2917,    1],\n",
       "        [1519,    1],\n",
       "        [ 659,    1],\n",
       "        [2085,    1],\n",
       "        [2109,    1],\n",
       "        [ 325,    1],\n",
       "        [ 314,    1],\n",
       "        [2224,    1],\n",
       "        [2076,    1],\n",
       "        [2044,    1],\n",
       "        [2436,    1],\n",
       "        [1299,    1],\n",
       "        [2265,    1],\n",
       "        [1339,    1],\n",
       "        [2089,    1],\n",
       "        [1336,    1],\n",
       "        [2275,    1],\n",
       "        [1280,    1],\n",
       "        [2152,    1],\n",
       "        [2864,    1],\n",
       "        [2318,    1],\n",
       "        [1993,    1],\n",
       "        [1441,    1],\n",
       "        [1274,    1],\n",
       "        [2413,    1],\n",
       "        [2059,    1],\n",
       "        [ 482,    1],\n",
       "        [2448,    1],\n",
       "        [1406,    1],\n",
       "        [2067,    1],\n",
       "        [2311,    1],\n",
       "        [ 481,    1],\n",
       "        [1286,    1],\n",
       "        [2673,    1],\n",
       "        [2190,    1],\n",
       "        [ 475,    1],\n",
       "        [2906,    1],\n",
       "        [1235,    1],\n",
       "        [2050,    1],\n",
       "        [2462,    1],\n",
       "        [2562,    1],\n",
       "        [1219,    1],\n",
       "        [1514,    1],\n",
       "        [ 464,    1],\n",
       "        [2426,    1],\n",
       "        [1948,    1],\n",
       "        [2173,    1],\n",
       "        [2852,    1],\n",
       "        [2254,    1],\n",
       "        [2850,    1],\n",
       "        [2169,    1],\n",
       "        [1437,    1],\n",
       "        [2849,    1],\n",
       "        [2447,    1],\n",
       "        [1352,    1],\n",
       "        [ 448,    1],\n",
       "        [ 509,    1],\n",
       "        [1494,    1],\n",
       "        [2208,    1],\n",
       "        [2453,    1],\n",
       "        [2456,    1],\n",
       "        [2222,    1],\n",
       "        [1949,    1],\n",
       "        [2141,    1],\n",
       "        [2246,    1],\n",
       "        [2291,    1],\n",
       "        [2333,    1],\n",
       "        [2884,    1],\n",
       "        [2287,    1],\n",
       "        [1297,    1],\n",
       "        [2683,    1],\n",
       "        [ 457,    1],\n",
       "        [2125,    1],\n",
       "        [2293,    1],\n",
       "        [ 148,    1],\n",
       "        [ 491,    1],\n",
       "        [2202,    1],\n",
       "        [2851,    1],\n",
       "        [1170,    1],\n",
       "        [2303,    1],\n",
       "        [1438,    1],\n",
       "        [2894,    1],\n",
       "        [1509,    1],\n",
       "        [ 303,    1],\n",
       "        [1952,    1],\n",
       "        [2229,    1],\n",
       "        [1985,    1],\n",
       "        [2007,    1],\n",
       "        [1221,    1],\n",
       "        [2976,    2],\n",
       "        [2689,    2],\n",
       "        [2639,    2],\n",
       "        [  46,    2],\n",
       "        [ 255,    2],\n",
       "        [ 107,    2],\n",
       "        [  85,    2],\n",
       "        [ 524,    2],\n",
       "        [ 760,    2],\n",
       "        [2605,    2],\n",
       "        [2801,    2],\n",
       "        [2525,    2],\n",
       "        [ 422,    2],\n",
       "        [ 715,    2],\n",
       "        [ 211,    2],\n",
       "        [2844,    2],\n",
       "        [ 348,    2],\n",
       "        [ 272,    2],\n",
       "        [  10,    2],\n",
       "        [ 389,    2],\n",
       "        [ 419,    2],\n",
       "        [ 101,    2],\n",
       "        [  61,    2],\n",
       "        [2650,    2],\n",
       "        [2721,    2],\n",
       "        [2619,    2],\n",
       "        [2516,    2],\n",
       "        [ 725,    2],\n",
       "        [3006,    2],\n",
       "        [2806,    2],\n",
       "        [ 350,    2],\n",
       "        [2939,    2],\n",
       "        [ 327,    2],\n",
       "        [2800,    2],\n",
       "        [ 237,    2],\n",
       "        [ 391,    2],\n",
       "        [   9,    2],\n",
       "        [2714,    2],\n",
       "        [ 176,    2],\n",
       "        [ 204,    2],\n",
       "        [ 627,    2],\n",
       "        [ 767,    2],\n",
       "        [ 188,    2],\n",
       "        [ 718,    2],\n",
       "        [  25,    2],\n",
       "        [ 635,    2],\n",
       "        [ 574,    2],\n",
       "        [  38,    2],\n",
       "        [2660,    2],\n",
       "        [ 645,    2],\n",
       "        [ 276,    2],\n",
       "        [2765,    2],\n",
       "        [ 349,    2],\n",
       "        [ 291,    2],\n",
       "        [  59,    2],\n",
       "        [2614,    2],\n",
       "        [ 332,    2],\n",
       "        [2755,    2],\n",
       "        [2808,    2],\n",
       "        [ 240,    2],\n",
       "        [ 428,    2],\n",
       "        [ 607,    2],\n",
       "        [ 118,    2],\n",
       "        [2477,    2],\n",
       "        [3017,    2],\n",
       "        [2978,    2],\n",
       "        [2814,    2],\n",
       "        [2489,    2],\n",
       "        [ 200,    2],\n",
       "        [2621,    2],\n",
       "        [ 780,    2],\n",
       "        [ 412,    2],\n",
       "        [ 732,    2],\n",
       "        [2656,    2],\n",
       "        [ 610,    2],\n",
       "        [ 692,    2],\n",
       "        [  73,    2],\n",
       "        [2632,    2],\n",
       "        [3009,    2],\n",
       "        [ 247,    2],\n",
       "        [2707,    2],\n",
       "        [2820,    2],\n",
       "        [  90,    2],\n",
       "        [ 700,    2],\n",
       "        [ 566,    2],\n",
       "        [  74,    2],\n",
       "        [ 577,    2],\n",
       "        [ 214,    2],\n",
       "        [ 637,    2],\n",
       "        [ 435,    2],\n",
       "        [ 253,    2],\n",
       "        [2669,    2],\n",
       "        [ 684,    2],\n",
       "        [2740,    2],\n",
       "        [2535,    2],\n",
       "        [ 532,    2],\n",
       "        [ 267,    2],\n",
       "        [ 361,    2],\n",
       "        [2599,    2],\n",
       "        [ 113,    2]], dtype=int64),\n",
       " array([[   0,    2],\n",
       "        [   1,    2],\n",
       "        [   2,    2],\n",
       "        ...,\n",
       "        [3022,    2],\n",
       "        [3023,    2],\n",
       "        [3024,    2]], dtype=int64)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da47deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = edges[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b2c7ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, edge in enumerate(edges):\n",
    "    if i == 0:\n",
    "        A = torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1)\n",
    "    else:\n",
    "        A = torch.cat([A, torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1)], dim=-1)\n",
    "A = torch.cat([A, torch.eye(num_nodes).type(torch.FloatTensor).unsqueeze(-1)], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc348353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf86ad94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8994, 8994, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fae5b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features = torch.from_numpy(node_features).type(torch.FloatTensor)\n",
    "train_node = torch.from_numpy(np.array(labels[0])[:, 0]).type(torch.LongTensor)\n",
    "train_target = torch.from_numpy(np.array(labels[0])[:, 1]).type(torch.LongTensor)\n",
    "valid_node = torch.from_numpy(np.array(labels[1])[:, 0]).type(torch.LongTensor)\n",
    "valid_target = torch.from_numpy(np.array(labels[1])[:, 1]).type(torch.LongTensor)\n",
    "test_node = torch.from_numpy(np.array(labels[2])[:, 0]).type(torch.LongTensor)\n",
    "test_target = torch.from_numpy(np.array(labels[2])[:, 1]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21432712",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = torch.max(train_target).item() + 1\n",
    "final_f1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f98b3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GTN(num_edge=A.shape[-1],\n",
    "            num_channels=num_channels,\n",
    "            w_in=node_features.shape[1],\n",
    "            w_out=node_dim,\n",
    "            num_class=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            norm=norm)\n",
    "if adaptive_lr == 'false':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam([{'params': model.weight},\n",
    "                                  {'params': model.linear1.parameters()},\n",
    "                                  {'params': model.linear2.parameters()},\n",
    "                                  {\"params\": model.layers.parameters(), \"lr\": 0.5}\n",
    "                                  ], lr=0.005, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d39f4140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GTN(\n",
       "  (layers): ModuleList(\n",
       "    (0): GTLayer(\n",
       "      (conv1): GTConv()\n",
       "      (conv2): GTConv()\n",
       "    )\n",
       "    (1): GTLayer(\n",
       "      (conv1): GTConv()\n",
       "    )\n",
       "  )\n",
       "  (loss): CrossEntropyLoss()\n",
       "  (linear1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "183a8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "# Train & Valid\n",
    "best_train_loss = 10000\n",
    "best_val_loss = 10000\n",
    "best_train_f1 = 0\n",
    "best_val_f1 = 0\n",
    "best_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "411d6d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Train_Loss: 1.1074516773223877, Macro_F1: 0.18466687202453613\n",
      "Valid_Loss: 1.0783792734146118, Macro_F1: 0.4778386652469635\n",
      "Epoch:  2\n",
      "Train_Loss: 1.076841950416565, Macro_F1: 0.521491289138794\n",
      "Valid_Loss: 1.010503888130188, Macro_F1: 0.710550844669342\n",
      "Epoch:  3\n",
      "Train_Loss: 1.0047333240509033, Macro_F1: 0.7918422818183899\n",
      "Valid_Loss: 0.8797913789749146, Macro_F1: 0.8900139927864075\n",
      "Epoch:  4\n",
      "Train_Loss: 0.8665217161178589, Macro_F1: 0.9247635006904602\n",
      "Valid_Loss: 0.7209909558296204, Macro_F1: 0.8014833331108093\n",
      "Epoch:  5\n",
      "Train_Loss: 0.7036378979682922, Macro_F1: 0.86018967628479\n",
      "Valid_Loss: 0.6231492161750793, Macro_F1: 0.8641390800476074\n",
      "Epoch:  6\n",
      "Train_Loss: 0.5907576084136963, Macro_F1: 0.9215969443321228\n",
      "Valid_Loss: 0.532245934009552, Macro_F1: 0.8286805152893066\n",
      "Epoch:  7\n",
      "Train_Loss: 0.5095663666725159, Macro_F1: 0.8583758473396301\n",
      "Valid_Loss: 0.427819162607193, Macro_F1: 0.8594194054603577\n",
      "Epoch:  8\n",
      "Train_Loss: 0.3975590467453003, Macro_F1: 0.9062349200248718\n",
      "Valid_Loss: 0.40849533677101135, Macro_F1: 0.8912549614906311\n",
      "Epoch:  9\n",
      "Train_Loss: 0.3493770658969879, Macro_F1: 0.9254019260406494\n",
      "Valid_Loss: 0.32436516880989075, Macro_F1: 0.9004690647125244\n",
      "Epoch:  10\n",
      "Train_Loss: 0.27233201265335083, Macro_F1: 0.9348792433738708\n",
      "Valid_Loss: 0.2794591188430786, Macro_F1: 0.9090089201927185\n",
      "Epoch:  11\n",
      "Train_Loss: 0.23999185860157013, Macro_F1: 0.9443964958190918\n",
      "Valid_Loss: 0.24826471507549286, Macro_F1: 0.926173210144043\n",
      "Epoch:  12\n",
      "Train_Loss: 0.1940171867609024, Macro_F1: 0.9445263743400574\n",
      "Valid_Loss: 0.238190695643425, Macro_F1: 0.9265289306640625\n",
      "Epoch:  13\n",
      "Train_Loss: 0.15697301924228668, Macro_F1: 0.9483088850975037\n",
      "Valid_Loss: 0.23647329211235046, Macro_F1: 0.9107264876365662\n",
      "Epoch:  14\n",
      "Train_Loss: 0.13555938005447388, Macro_F1: 0.9616624712944031\n",
      "Valid_Loss: 0.23337872326374054, Macro_F1: 0.9107264876365662\n",
      "Epoch:  15\n",
      "Train_Loss: 0.11594881862401962, Macro_F1: 0.9599819183349609\n",
      "Valid_Loss: 0.2201005071401596, Macro_F1: 0.9270077347755432\n",
      "Epoch:  16\n",
      "Train_Loss: 0.09395181387662888, Macro_F1: 0.9649913907051086\n",
      "Valid_Loss: 0.20246659219264984, Macro_F1: 0.9303022027015686\n",
      "Epoch:  17\n",
      "Train_Loss: 0.07612758129835129, Macro_F1: 0.9682863354682922\n",
      "Valid_Loss: 0.1995198130607605, Macro_F1: 0.9334511756896973\n",
      "Epoch:  18\n",
      "Train_Loss: 0.0670320987701416, Macro_F1: 0.9732419848442078\n",
      "Valid_Loss: 0.20265190303325653, Macro_F1: 0.9401242733001709\n",
      "Epoch:  19\n",
      "Train_Loss: 0.05554768815636635, Macro_F1: 0.9799664616584778\n",
      "Valid_Loss: 0.2061765342950821, Macro_F1: 0.9303276538848877\n",
      "Epoch:  20\n",
      "Train_Loss: 0.045748837292194366, Macro_F1: 0.9816527366638184\n",
      "Valid_Loss: 0.21279165148735046, Macro_F1: 0.9269303679466248\n",
      "Epoch:  21\n",
      "Train_Loss: 0.03764215484261513, Macro_F1: 0.9883326888084412\n",
      "Valid_Loss: 0.21947187185287476, Macro_F1: 0.926975429058075\n",
      "Epoch:  22\n",
      "Train_Loss: 0.030029498040676117, Macro_F1: 0.9933333396911621\n",
      "Valid_Loss: 0.22836126387119293, Macro_F1: 0.9270077347755432\n",
      "Epoch:  23\n",
      "Train_Loss: 0.026628494262695312, Macro_F1: 0.9949999451637268\n",
      "Valid_Loss: 0.24152442812919617, Macro_F1: 0.9302615523338318\n",
      "Epoch:  24\n",
      "Train_Loss: 0.02300826646387577, Macro_F1: 0.9933326244354248\n",
      "Valid_Loss: 0.24076440930366516, Macro_F1: 0.9269303679466248\n",
      "Epoch:  25\n",
      "Train_Loss: 0.017703669145703316, Macro_F1: 1.0\n",
      "Valid_Loss: 0.24210067093372345, Macro_F1: 0.9203564524650574\n",
      "Epoch:  26\n",
      "Train_Loss: 0.015838639810681343, Macro_F1: 1.0\n",
      "Valid_Loss: 0.25108712911605835, Macro_F1: 0.926978588104248\n",
      "Epoch:  27\n",
      "Train_Loss: 0.012712076306343079, Macro_F1: 0.9983332753181458\n",
      "Valid_Loss: 0.25289231538772583, Macro_F1: 0.926978588104248\n",
      "Epoch:  28\n",
      "Train_Loss: 0.01037363987416029, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2502390444278717, Macro_F1: 0.9235866665840149\n",
      "Epoch:  29\n",
      "Train_Loss: 0.00883980467915535, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2538960874080658, Macro_F1: 0.9235866665840149\n",
      "Epoch:  30\n",
      "Train_Loss: 0.007065549027174711, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2615486681461334, Macro_F1: 0.9202089309692383\n",
      "Epoch:  31\n",
      "Train_Loss: 0.00605411920696497, Macro_F1: 1.0\n",
      "Valid_Loss: 0.26509037613868713, Macro_F1: 0.9202089309692383\n",
      "Epoch:  32\n",
      "Train_Loss: 0.005152080673724413, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2653333842754364, Macro_F1: 0.9235866665840149\n",
      "Epoch:  33\n",
      "Train_Loss: 0.004135653842240572, Macro_F1: 1.0\n",
      "Valid_Loss: 0.26899397373199463, Macro_F1: 0.930241584777832\n",
      "Epoch:  34\n",
      "Train_Loss: 0.003782982937991619, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2731020152568817, Macro_F1: 0.930241584777832\n",
      "Epoch:  35\n",
      "Train_Loss: 0.0030832320917397738, Macro_F1: 1.0\n",
      "Valid_Loss: 0.27818286418914795, Macro_F1: 0.9202523231506348\n",
      "Epoch:  36\n",
      "Train_Loss: 0.002651063259691, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2831726670265198, Macro_F1: 0.917087733745575\n",
      "Epoch:  37\n",
      "Train_Loss: 0.0024647710379213095, Macro_F1: 1.0\n",
      "Valid_Loss: 0.286016583442688, Macro_F1: 0.9204080700874329\n",
      "Epoch:  38\n",
      "Train_Loss: 0.002116989344358444, Macro_F1: 1.0\n",
      "Valid_Loss: 0.2885638177394867, Macro_F1: 0.9171044230461121\n",
      "Epoch:  39\n",
      "Train_Loss: 0.0018513691611588001, Macro_F1: 1.0\n",
      "Valid_Loss: 0.29201528429985046, Macro_F1: 0.9171062111854553\n",
      "Epoch:  40\n",
      "Train_Loss: 0.0017687974032014608, Macro_F1: 1.0\n",
      "Valid_Loss: 0.29479992389678955, Macro_F1: 0.9138864874839783\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        if param_group['lr'] > 0.005:\n",
    "            param_group['lr'] = param_group['lr'] * 0.9\n",
    "    print('Epoch: ', i + 1)\n",
    "    model.zero_grad()\n",
    "    model.train()\n",
    "    loss, y_train, Ws = model(A, node_features, train_node, train_target)\n",
    "    train_f1 = torch.mean(\n",
    "        f1_score(torch.argmax(y_train.detach(), dim=1), train_target, num_classes=num_classes)).cpu().numpy()\n",
    "    print('Train_Loss: {}, Macro_F1: {}'.format(loss.detach().cpu().numpy(), train_f1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # Valid\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss, y_valid, _ = model.forward(A, node_features, valid_node, valid_target)\n",
    "        val_f1 = torch.mean(\n",
    "            f1_score(torch.argmax(y_valid, dim=1), valid_target, num_classes=num_classes)).cpu().numpy()\n",
    "        print('Valid_Loss: {}, Macro_F1: {}'.format(val_loss.detach().cpu().numpy(), val_f1))\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_train_loss = loss.detach().cpu().numpy()\n",
    "        best_val_loss = val_loss.detach().cpu().numpy()\n",
    "        best_train_f1 = train_f1\n",
    "        best_val_f1 = val_f1\n",
    "        best_epoch = i + 1\n",
    "        torch.save(model.state_dict(), \"model_pth/best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1a2a738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Test----------------\n",
      "Best Epoch:  18\n",
      "Train_Loss: 0.0670320987701416, Macro_F1: 0.9732419848442078\n",
      "Valid_Loss: 0.20265190303325653, Macro_F1: 0.9401242733001709\n",
      "Test_Loss: 0.23855070769786835, Macro_F1: 0.9202559590339661\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "model.load_state_dict(torch.load(\"model_pth/best.pth\"))\n",
    "model.eval()\n",
    "print('----------------Test----------------')\n",
    "with torch.no_grad():\n",
    "    best_test_loss, y_test, W = model.forward(A, node_features, test_node, test_target)\n",
    "    best_test_f1 = torch.mean(f1_score(torch.argmax(y_test, dim=1), test_target, num_classes=num_classes)).cpu().numpy()\n",
    "print('Best Epoch: ', best_epoch)\n",
    "print('Train_Loss: {}, Macro_F1: {}'.format(best_train_loss, best_train_f1))\n",
    "print('Valid_Loss: {}, Macro_F1: {}'.format(best_val_loss, best_val_f1))\n",
    "print('Test_Loss: {}, Macro_F1: {}'.format(best_test_loss, best_test_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
